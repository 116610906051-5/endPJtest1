import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from xgboost import XGBClassifier
import joblib
import warnings
warnings.filterwarnings('ignore')

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df = pd.read_csv("../dataset.csv")

# ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN
df = df.dropna()

# ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Title ‡πÄ‡∏õ‡πá‡∏ô text ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á Verification_Status ‡πÄ‡∏õ‡πá‡∏ô label (0/1)
texts = df["Title"]
labels = df["Verification_Status"].map({"‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°": 0, "‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á": 1})

print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
print(f"‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°: {(labels == 0).sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
print(f"‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á: {(labels == 1).sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

# 2. ‡πÅ‡∏ö‡πà‡∏á train / test
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42
)

# 3. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (TF-IDF)
vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

print("\n" + "="*60)
print("üîç ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß")
print("="*60)

# 4. ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß
models = {
    "LinearSVC": LinearSVC(random_state=42, max_iter=2000),
    "XGBoost": XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1, verbosity=0),
    "Random Forest": RandomForestClassifier(random_state=42, n_estimators=100),
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000)
}

model_scores = {}
for name, model in models.items():
    print(f"\nüìä {name}:")
    model.fit(X_train_vec, y_train)
    y_pred = model.predict(X_test_vec)
    accuracy = accuracy_score(y_test, y_pred)
    model_scores[name] = accuracy
    print(f"Accuracy: {accuracy:.4f}")

# 5. Ensemble Model - Voting Classifier (Soft Voting)
print("\n" + "="*60)
print("üéØ Ensemble Model - Voting Classifier")
print("="*60)

voting_model = VotingClassifier(
    estimators=[
        ('svm', LinearSVC(random_state=42, max_iter=2000)),
        ('xgb', XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1, verbosity=0)),
        ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),
        ('lr', LogisticRegression(random_state=42, max_iter=1000))
    ],
    voting='hard'  # hard voting ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ LinearSVC ‡πÑ‡∏°‡πà‡∏°‡∏µ predict_proba
)

voting_model.fit(X_train_vec, y_train)
y_pred_voting = voting_model.predict(X_test_vec)
voting_accuracy = accuracy_score(y_test, y_pred_voting)
print(f"Voting Ensemble Accuracy: {voting_accuracy:.4f}")

# 6. Ensemble Model - Stacking Classifier
print("\n" + "="*60)
print("üöÄ Ensemble Model - Stacking Classifier")
print("="*60)

stacking_model = StackingClassifier(
    estimators=[
        ('xgb', XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1, verbosity=0)),
        ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),
        ('svm', LinearSVC(random_state=42, max_iter=2000))
    ],
    final_estimator=LogisticRegression(random_state=42, max_iter=1000)
)

stacking_model.fit(X_train_vec, y_train)
y_pred_stacking = stacking_model.predict(X_test_vec)
stacking_accuracy = accuracy_score(y_test, y_pred_stacking)
print(f"Stacking Ensemble Accuracy: {stacking_accuracy:.4f}")

# 7. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
print("\n" + "="*60)
print("üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
print("="*60)
for name, score in model_scores.items():
    print(f"{name:25s}: {score:.4f}")
print(f"{'Voting Ensemble':25s}: {voting_accuracy:.4f}")
print(f"{'Stacking Ensemble':25s}: {stacking_accuracy:.4f}")

# 8. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
best_model_name = max(
    [*model_scores.items(), ('Voting Ensemble', voting_accuracy), ('Stacking Ensemble', stacking_accuracy)],
    key=lambda x: x[1]
)[0]
print(f"\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model_name} ({max(voting_accuracy, stacking_accuracy, *model_scores.values()):.4f})")

# 9. Classification Report ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
print("\n" + "="*60)
print(f"üìä Classification Report - {best_model_name}")
print("="*60)
if best_model_name == "Voting Ensemble":
    print(classification_report(y_test, y_pred_voting, target_names=['‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°', '‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á']))
    final_model = voting_model
elif best_model_name == "Stacking Ensemble":
    print(classification_report(y_test, y_pred_stacking, target_names=['‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°', '‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á']))
    final_model = stacking_model
else:
    best_single_model = models[best_model_name]
    y_pred_best = best_single_model.predict(X_test_vec)
    print(classification_report(y_test, y_pred_best, target_names=['‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏•‡∏≠‡∏°', '‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á']))
    final_model = best_single_model

# 10. ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÉ‡∏ä‡πâ Stacking ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)
joblib.dump(stacking_model, "svm_model.pkl")  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô ensemble_model.pkl ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
joblib.dump(vectorizer, "tfidf.pkl")

print("\n‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß (Stacking Ensemble)")
